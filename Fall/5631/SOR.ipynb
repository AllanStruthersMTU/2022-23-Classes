{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f6e1192-0441-48e2-a3a7-941302fea81f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Alternate Names for Bits of Matrices\n",
    "We are looking at the traditional sparse solvers in Chapter 3.  Largely because they are easy to implement and monitor the convergence of.\n",
    "\n",
    "We want to solve $A x=b$ and we split a matrix $A=L+D+U$ into Lower Triangular, Diagonal, and Upper \n",
    "Triangular parts so we want to solve $(L+D+U) x^k = b$ where we have written $x^k$ to remind us that \n",
    "our target is an iterative solver we hope to have $x_k \\rightarrow x^\\infty = A^{-1} b$.\n",
    "\n",
    "Our book uses $E=-L$ and $F=-U$ which I find confusing. The $U$ and $L$ \n",
    "is much more standard. Expanding out in this notation we have Jacobi\n",
    "$$x^{k+1} = D^{-1} (E+F) x^k + D^{-1} b $$\n",
    "and Gauss-Seidel\n",
    "$$ x^{k+1} = (D-E)^{-1} F x^k + (D-E)^{-1} b $$\n",
    "and a new one called succesive over relaxation (SOR)\n",
    "which contains a parameter $\\omega$\n",
    "$$ x^{k+1} = (D-\\omega E)^{-1} \\left(\\omega F + (1-\\omega) D \\right) x^k + (D-\\omega E)^{-1} \\omega b $$\n",
    "The SOR iteration is has an iteration matrix \n",
    "$G_\\omega$ and vector $f_\\omega$ that defines the iteration\n",
    "$$\n",
    "x^{k+1} = G_\\omega x^k + f_\\omega\n",
    "$$\n",
    "There are other similar iterations along with block analogues and\n",
    "specialized symmetric solvers all have the same general form\n",
    "$$x^{k+1} = G x^k + f. $$\n",
    "As we will see (on the board) the convergence of all of these iterations is controlled by the\n",
    "eigenvalues of the iteration matrix $G$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c05098ac-9544-47c3-8bd2-dfbe8f673291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.014410 seconds (73 allocations: 3.570 MiB)\n",
      "  0.000076 seconds (6 allocations: 76.172 KiB)\n",
      "  0.000135 seconds (39 allocations: 357.312 KiB)\n",
      "  0.000097 seconds (32 allocations: 230.594 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SparseArrays, LinearAlgebra\n",
    "m=3234; dia=-4.0;\n",
    "A = spzeros(m,m)\n",
    "for i in 2:m\n",
    "    A[i,i]=dia; A[i-1,i]=A[i,i-1]=1.0\n",
    "end\n",
    "A[1,1]=dia\n",
    "A[m,1]=A[m,1]=1.0\n",
    "L=tril(A,-1); U=triu(A,1); D=tril(triu(A)) \n",
    "DU=D+U; UL=U+L\n",
    "b=rand(m);x=rand(m)\n",
    "@time BackSlashx=A\\b\n",
    "@time x=DU\\(b-L*x)\n",
    "@time x=D\\(b-(U+L)*x)\n",
    "@time x=D\\(b-(UL)*x)\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baba9bf-6669-4257-8b53-8c7ce91b22b0",
   "metadata": {},
   "source": [
    "We are going to look at the Gauss-Seidel iteration matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f4ef0e0-1ae4-44c3-89bd-9f8f08e19239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595.4120583319151"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "m=12; dia=-2.0;\n",
    "A = spzeros(m,m)\n",
    "for i in 2:m\n",
    "    A[i,i]=dia; A[i-1,i]=A[i,i-1]=1.0\n",
    "end\n",
    "A[1,1]=dia\n",
    "# A[m,1]=A[m,1]=1.0\n",
    "L=tril(A,-1); U=triu(A,1); D=tril(triu(A)) \n",
    "DU=D+U; UL=U+L\n",
    "G = inv(Matrix(DU))*L\n",
    "vals = eigen(G).values\n",
    "log(10^(-16))/log(0.94)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af10da-7664-4d03-b5a1-c03730ed5056",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Questions\n",
    "\n",
    "## How Do I Implement J and GS Efficiently?\n",
    "\n",
    "## When Do J and GS make sense?\n",
    "\n",
    "## When Do J and GS Converge?\n",
    "\n",
    "## How Fast do J and GS Converge?\n",
    "\n",
    "## Are there Block Analogues? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
